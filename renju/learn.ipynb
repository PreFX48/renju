{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from generate import *\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SL Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_classes = 225\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(padding=(2, 2), input_shape=INPUT_SHAPE))\n",
    "model.add(Convolution2D(16, 5,\n",
    "                        padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution2D(32, 5,\n",
    "                        padding='valid')) # same\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution2D(32, 5,\n",
    "                        padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(48, 5,\n",
    "                        padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      \n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "model.save('large_policy_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [('all', load_model('large_policy_model')),\n",
    "          ('+10', load_model('large_policy_model_10')),\n",
    "          ('+10+1', load_model('large_policy_model_10_1'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    acc = [model[1].evaluate_generator(generator=generate_batch('aug_test.renju', 4096, last_n=n), steps=32)[1]\n",
    "         for n in [None, 10, 1]]\n",
    "    print('{}: {}%, {}%, {}%'.format(model[0], round(acc[0]*100), round(acc[1]*100), round(acc[2]*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Повторяющаяся часть для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 2048\n",
    "EPOCH_SIZE = 131072 # 1048576 # 8388608\n",
    "EPOCH_VAL_SIZE = 131072 # 262144\n",
    "STEPS = EPOCH_SIZE // BATCH_SIZE\n",
    "VAL_STEPS = EPOCH_VAL_SIZE // BATCH_SIZE\n",
    "\n",
    "train_file = 'aug_train.renju'\n",
    "test_file = 'aug_test.renju'\n",
    "callbacks = [ModelCheckpoint('large_policy_model', period=5),\n",
    "             TensorBoard(log_dir='./tensorboard_policy')]\n",
    "\n",
    "print('Start time:', time.ctime())\n",
    "\n",
    "model = load_model('large_policy_model')\n",
    "history = model.fit_generator(generator=generate_batch(train_file, BATCH_SIZE, last_n=1),\n",
    "                    steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "                    validation_data=generate_batch(test_file, BATCH_SIZE, last_n=1),\n",
    "                    validation_steps=VAL_STEPS, callbacks=callbacks)\n",
    "model.save('large_policy_model')\n",
    "    \n",
    "print('Finish time:', time.ctime())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Value network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(padding=(2, 2), input_shape=INPUT_SHAPE))\n",
    "model.add(Convolution2D(16, (5, 5),\n",
    "                        padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution2D(16, (5, 5),\n",
    "                        padding='valid')) # same\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))  # 1024\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=\"adadelta\")\n",
    "model.save('value_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 4096\n",
    "EPOCH_SIZE = 524288\n",
    "EPOCH_VAL_SIZE = 131072\n",
    "STEPS = EPOCH_SIZE // BATCH_SIZE\n",
    "VAL_STEPS = EPOCH_VAL_SIZE // BATCH_SIZE\n",
    "\n",
    "train_file = 'aug_train.renju'\n",
    "test_file = 'aug_test.renju'\n",
    "\n",
    "print('Start time:', time.ctime())\n",
    "\n",
    "model = load_model('value_model')\n",
    "history = model.fit_generator(generator=generate_batch(train_file, BATCH_SIZE, mark_player=True, last_n=20),\n",
    "                    steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "                    validation_data=generate_batch(test_file, BATCH_SIZE, mark_player=True, last_n=20),\n",
    "                    validation_steps=VAL_STEPS, callbacks=[TensorBoard(log_dir='tensorboard', histogram_freq=1)])\n",
    "model.save('value_model')\n",
    "    \n",
    "print('Finish time:', time.ctime())\n",
    "    \n",
    "# plt.figure(figsize=(30, 5))\n",
    "# acc_history = list(map(lambda x: x, history.history['loss']))\n",
    "# val_acc_history = list(map(lambda x: x, history.history['val_loss']))\n",
    "# y_ticks = np.linspace(0, 2, 11)\n",
    "# y_labels = np.vectorize(lambda x: str(round(x, 1)) + \"%\")(y_ticks)\n",
    "# plt.plot(range(1, EPOCHS+1), acc_history, 'b', label='loss')\n",
    "# plt.plot(range(1, EPOCHS+1), val_acc_history, 'r', label='val_loss')\n",
    "# plt.yticks(y_ticks, y_labels)\n",
    "# plt.grid(True)\n",
    "# plt.legend(loc='upper left', fontsize=16)\n",
    "# plt.savefig('value_history.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = generate_batch('aug_train.renju', 1, mark_player=True, last_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = next(gen)\n",
    "print(y1)\n",
    "print(model.predict(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_dataset('aug_train.renju', mark_player=True, last_n=20, nb_games=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
