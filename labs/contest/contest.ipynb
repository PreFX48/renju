{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "import pandas\n",
    "\n",
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')\n",
    "        \n",
    "def compare_img(img1, img2):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('train.npy')\n",
    "\n",
    "train_samples = data[:125000, 0]\n",
    "train_labels = data[:125000, 1]\n",
    "test_samples = data[125000:, 0]\n",
    "test_labels = data[125000:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_ROWS = 60\n",
    "IMG_COLUMNS = 60\n",
    "mean_image = np.zeros((IMG_ROWS, IMG_COLUMNS), dtype='float32')\n",
    "for i in log_progress(range(train_samples.shape[0]), every=50):\n",
    "    img = imresize(train_samples[i], (IMG_ROWS, IMG_COLUMNS), interp='lanczos')\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    img = exposure.rescale_intensity(img)\n",
    "    train_samples[i] = img\n",
    "    mean_image += img\n",
    "for i in log_progress(range(test_samples.shape[0]), every=50):\n",
    "    img = imresize(test_samples[i], (IMG_ROWS, IMG_COLUMNS), interp='lanczos')\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    img = exposure.rescale_intensity(img)\n",
    "    test_samples[i] = img\n",
    "    mean_image += img\n",
    "    \n",
    "mean_image /= (train_samples.shape[0] + test_samples.shape[0])\n",
    "for i in log_progress(range(train_samples.shape[0]), every=50):\n",
    "    train_samples[i] -= mean_image\n",
    "for i in log_progress(range(test_samples.shape[0]), every=50):\n",
    "    test_samples[i] -= mean_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_samples = np.dstack(train_samples).transpose((2, 0, 1))\n",
    "test_samples = np.dstack(test_samples).transpose((2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minLabel = np.min(train_labels)\n",
    "maxLabel = np.max(train_labels)\n",
    "print('range from', minLabel, 'to', maxLabel)\n",
    "sorted_labels = sorted(train_labels.tolist())\n",
    "unique_labels = []\n",
    "for k, g in itertools.groupby(sorted_labels):\n",
    "    unique_labels.append(k)\n",
    "print(len(unique_labels), 'unique labels')\n",
    "\n",
    "labels_to_indices = dict()\n",
    "indices_to_labels = dict()\n",
    "for i in range(len(unique_labels)):\n",
    "    labels_to_indices[unique_labels[i]] = i\n",
    "    indices_to_labels[i] = unique_labels[i]\n",
    "\n",
    "new_train_labels = np.vectorize(lambda x: labels_to_indices[x])(train_labels)\n",
    "new_test_labels = np.vectorize(lambda x: labels_to_indices[x])(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    train_samples = train_samples.reshape(train_samples.shape[0], 1, IMG_ROWS, IMG_COLUMNS)\n",
    "    test_samples = test_samples.reshape(test_samples.shape[0], 1, IMG_ROWS, IMG_COLUMNS)\n",
    "    input_shape = (1, IMG_ROWS, IMG_COLUMNS)\n",
    "else:\n",
    "    train_samples = train_samples.reshape(train_samples.shape[0], IMG_ROWS, IMG_COLUMNS, 1)\n",
    "    test_samples = test_samples.reshape(test_samples.shape[0], IMG_ROWS, IMG_COLUMNS, 1)\n",
    "    input_shape = (IMG_ROWS, IMG_COLUMNS, 1)\n",
    "\n",
    "batch_size = 256\n",
    "nb_classes = len(unique_labels)\n",
    "nb_epoch = 30\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(new_train_labels, nb_classes)\n",
    "Y_test = np_utils.to_categorical(new_test_labels, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_samples, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(test_samples, Y_test))\n",
    "score = model.evaluate(test_samples, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "public_data = np.load('test.npy')\n",
    "\n",
    "for i in log_progress(range(public_data.shape[0]), every=50):\n",
    "    img = imresize(public_data[i], (IMG_ROWS, IMG_COLUMNS), interp='lanczos')\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    img = exposure.rescale_intensity(img)\n",
    "    img -= mean_image\n",
    "    public_data[i] = img\n",
    "public_data = np.dstack(public_data).transpose((2, 0, 1))\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    public_data = public_data.reshape(public_data.shape[0], 1, IMG_ROWS, IMG_COLUMNS)\n",
    "else:\n",
    "    public_data = public_data.reshape(public_data.shape[0], IMG_ROWS, IMG_COLUMNS, 1)\n",
    "    \n",
    "raw_result = model.predict_classes(public_data)\n",
    "result = np.vectorize(lambda x: indices_to_labels[x])(raw_result).reshape((raw_result.shape[0], 1))\n",
    "ids = np.arange(1, result.shape[0]+1).reshape((result.shape[0], 1))\n",
    "table = np.hstack((ids, result))\n",
    "\n",
    "df = pandas.DataFrame(table)\n",
    "df.columns = ['Id', 'Category']\n",
    "df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "165078dbfeff4739a054151995b2787e": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "280278fdcae944df9cbc383307b4ade5": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "2dcaae92d164416d94738112f682d00d": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "2ebadc1fdb024718aa09c6f602df27f1": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "822a252fa2c94c888be75cd0d0ac4b70": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "b6e4cad1b3084c118aad75388e27ed76": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "c28cafb7e45b4add9037499e0d394b5e": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "d2ac6030dc0c4cb392187a70b5a9622c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "dac3ddc43ad048249580b017ad1aaf88": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "ee2fb3a931ad48158c9ed1231b5077e6": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "fa86a3423e084469808e0eeadda23a69": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
